{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f2a73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:20.013162Z",
     "iopub.status.busy": "2024-09-05T15:22:20.012252Z",
     "iopub.status.idle": "2024-09-05T15:22:28.438889Z",
     "shell.execute_reply": "2024-09-05T15:22:28.438441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 16:22:26.291519: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Process Name            : STEP 6 : PROTOTYPE MODEL\n",
    "\"\"\"\n",
    "#=======================================================================================================\n",
    "### Required Imports ###\n",
    "#============================================================================================================\n",
    "try:\n",
    "    import sys  # System-specific parameters and functions\n",
    "    import logging # for logs\n",
    "    import socket # network communication\n",
    "    import warnings  # Warning control\n",
    "    import os # Interacting with the operating system\n",
    "    import pandas as pd  # Data handling\n",
    "    import numpy as np  # Numerical operations\n",
    "    import difflib  # Sequence matching\n",
    "    import pycountry  # Country data\n",
    "    from geopy.geocoders import Nominatim  # Geocoding\n",
    "    import re  # Regex\n",
    "    from datetime import datetime  # Date/time\n",
    "    from matplotlib import colors  # Color utilities\n",
    "    from spellchecker import SpellChecker  # Spell check\n",
    "    from sklearn.model_selection import train_test_split  # Data splitting\n",
    "    from colour import Color  # Color manipulation\n",
    "    import nltk  # NLP toolkit\n",
    "    from nltk.corpus import stopwords  # Stopwords\n",
    "    import seaborn as sns  # Visualization\n",
    "    import matplotlib.pyplot as plt  # Plotting\n",
    "    import json  # JSON handling\n",
    "    from sklearn.ensemble import RandomForestClassifier  # Random Forest\n",
    "    import lightgbm as lgb  # LightGBM\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Metrics\n",
    "    from sklearn.multioutput import MultiOutputClassifier  # Multi-output classifier\n",
    "    from sklearn.preprocessing import LabelEncoder  # Label encoding\n",
    "    import xgboost as xgb  # XGBoost\n",
    "    from joblib import dump, load  # Model saving/loading\n",
    "    from sklearn.cluster import KMeans  # Clustering\n",
    "    from sklearn.preprocessing import StandardScaler  # Feature scaling\n",
    "    from sklearn.preprocessing import MinMaxScaler  # Min-max scaling\n",
    "    from tensorflow.keras.models import Sequential  # Neural network\n",
    "    from tensorflow.keras.layers import LSTM, Dense  # LSTM and Dense layers\n",
    "    from tensorflow.keras.callbacks import EarlyStopping  # Early stopping\n",
    "    from tensorflow.keras.models import load_model #for model loading\n",
    "    from selenium import webdriver  # Web browser automation\n",
    "    from selenium.webdriver.common.by import By  # Locate elements on a page\n",
    "    from selenium.webdriver.support import expected_conditions  # Wait for conditions to be met\n",
    "    from selenium.webdriver.support.wait import WebDriverWait  # Explicit wait\n",
    "    from selenium.webdriver.common.keys import Keys  # Keyboard actions\n",
    "    from selenium.webdriver.chrome.options import Options  # Chrome browser options\n",
    "    from selenium.webdriver.support import expected_conditions as EC  # Alias for expected conditions\n",
    "    from selenium.webdriver.support.ui import Select  # Handle dropdown menus\n",
    "    from selenium.webdriver.chrome.service import Service  # Manage ChromeDriver service\n",
    "    from time import sleep  # Pause execution\n",
    "    import requests  # Send HTTP requests\n",
    "except Exception as err:\n",
    "    print(\"Exception raised while importing the packages\")\n",
    "    print(f'Exception: {err}')\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a543bd11-d19f-4f53-8bb3-fd62c53c9a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.441571Z",
     "iopub.status.busy": "2024-09-05T15:22:28.441276Z",
     "iopub.status.idle": "2024-09-05T15:22:28.447755Z",
     "shell.execute_reply": "2024-09-05T15:22:28.447432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,446 : INFO : [3048668818.py:45] : Process start\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================\n",
    "### Initialization ###\n",
    "#=========================================================================\n",
    "try:\n",
    "    path = os.getcwd()\n",
    "    curr_time = datetime.now()\n",
    "\n",
    "    ### Log Files declaration ###\n",
    "    log_folder = os.path.join(path, 'Logs')\n",
    "    log_date_fmt = str(curr_time.strftime('%Y')) + '-' + str(curr_time.strftime('%m')) + '-' + str(curr_time.strftime('%d')) + \"_\" + str(curr_time.strftime(\"%H\")) + \"-\" + str(curr_time.strftime(\"%M\"))\n",
    "\n",
    "    audit_log_file = \"Audit_prototype_model.log\"\n",
    "    audit_log_file = os.path.join(log_folder, audit_log_file)\n",
    "    \n",
    "    error_log_file = \"Error_prototype_model.log\"\n",
    "    error_log_file = os.path.join(log_folder, error_log_file)\n",
    "\n",
    "    ### Creating log folder ###\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder)\n",
    "        \n",
    "    ### Function: Logger setup ###\n",
    "    def setup_logger(logger_name, log_file, level=logging.INFO):\n",
    "        logger = logging.getLogger(logger_name)\n",
    "        formatter = logging.Formatter(socket.gethostname()+' : '+'%(asctime)s : %(levelname)s : [%(filename)s:%(lineno)d] : %(message)s')\n",
    "\n",
    "        fileHandler = logging.FileHandler(log_file, mode='w')\n",
    "\n",
    "        fileHandler.setFormatter(formatter)\n",
    "\n",
    "        streamHandler = logging.StreamHandler(sys.stdout)\n",
    "        streamHandler.setFormatter(formatter)\n",
    "\n",
    "        logger.setLevel(level)\n",
    "        logger.addHandler(fileHandler)\n",
    "        logger.addHandler(streamHandler)\n",
    "        return logger\n",
    "        \n",
    "    ### Setting up the logger ###\n",
    "    setup_logger('audit', audit_log_file, level=logging.INFO)\n",
    "    setup_logger('error', error_log_file, level=logging.ERROR)\n",
    "\n",
    "    audit_logger = logging.getLogger('audit')\n",
    "    error_logger = logging.getLogger('error')\n",
    "    audit_logger.info('Process start')\n",
    "\n",
    "except Exception as err:\n",
    "    print('Setting up the logger failed')\n",
    "    print(f'Exception: {err}')\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9433dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.449716Z",
     "iopub.status.busy": "2024-09-05T15:22:28.449567Z",
     "iopub.status.idle": "2024-09-05T15:22:28.452378Z",
     "shell.execute_reply": "2024-09-05T15:22:28.452076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,450 : INFO : [2561458356.py:5] : Ignore Warnings\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Ignore Warnings ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Ignore Warnings')\n",
    "    warnings.filterwarnings('ignore') ## Suppress all warnings\n",
    "except Exception as err:\n",
    "    audit_logger.info('Ignore Warnings - Failed')\n",
    "    error_logger.error('Ignore Warnings - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935e3311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.454335Z",
     "iopub.status.busy": "2024-09-05T15:22:28.454186Z",
     "iopub.status.idle": "2024-09-05T15:22:28.660360Z",
     "shell.execute_reply": "2024-09-05T15:22:28.660008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,455 : INFO : [1589805589.py:5] : Downloading NLTK STOPWAORDS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shrutipatkar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Download NLTK STOPWAORDS ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Downloading NLTK STOPWAORDS')\n",
    "    spell = SpellChecker()\n",
    "    nltk.download('stopwords') # Download the stopwords from NLTK\n",
    "    stop_words = set(stopwords.words('english')) # Create a set of English stopwords\n",
    "except Exception as err:\n",
    "    audit_logger.info('Downloading NLTK STOPWAORDS - Failed')\n",
    "    error_logger.error('Downloading NLTK STOPWAORDS - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e051416-9bcb-49e4-8a81-0c59b6f83270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.662833Z",
     "iopub.status.busy": "2024-09-05T15:22:28.662664Z",
     "iopub.status.idle": "2024-09-05T15:22:28.667110Z",
     "shell.execute_reply": "2024-09-05T15:22:28.666730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,665 : INFO : [300162134.py:5] : Create folder structure\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Create folder structure ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Create folder structure')\n",
    "    path\n",
    "    input_folder = os.path.join(path, 'Input')\n",
    "    if not os.path.isdir(input_folder):\n",
    "        audit_logger.info('No input folder')\n",
    "        error_logger.error('No input folder')\n",
    "        raise Exception\n",
    "    excel_folder = os.path.join(path, 'Excel_files')\n",
    "    if not os.path.isdir(excel_folder):\n",
    "        os.mkdir(excel_folder)\n",
    "    saved_folder = os.path.join(path, 'Saved_files')\n",
    "    if not os.path.isdir(saved_folder):\n",
    "        os.mkdir(saved_folder)\n",
    "    output_folder = os.path.join(path, 'Output')\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "except Exception as err:\n",
    "    audit_logger.info('Create folder structure - Failed')\n",
    "    error_logger.error('Create folder structure - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959e810c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.669565Z",
     "iopub.status.busy": "2024-09-05T15:22:28.669389Z",
     "iopub.status.idle": "2024-09-05T15:22:28.687811Z",
     "shell.execute_reply": "2024-09-05T15:22:28.687482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,685 : INFO : [3680746.py:1] : Saving Functions\n"
     ]
    }
   ],
   "source": [
    "audit_logger.info('Saving Functions') \n",
    "# Function to find the best match and its confidence\n",
    "def get_best_match_with_confidence(country):\n",
    "    country = country.replace(\"City\", \"\") #drop word \"City\n",
    "    if \"Englan\" in country:\n",
    "        country = \"United Kingdom\"\n",
    "    if \"rkiye\" in country and country.startswith(\"T\"):\n",
    "        country = \"Turkey\"\n",
    "    try:\n",
    "        try:\n",
    "            country = alpha_2_mapping[country]\n",
    "        except:\n",
    "            pass\n",
    "        matches = difflib.get_close_matches(country, country_names, n=1)\n",
    "        if matches:\n",
    "            best_match = matches[0]\n",
    "            confidence = difflib.SequenceMatcher(None, country, best_match).ratio() #calculate the confidence level (0 to 1)\n",
    "            if confidence >= 0.80:\n",
    "                return best_match, confidence\n",
    "            else:\n",
    "                return country, 0            \n",
    "        else:\n",
    "            return country, 0\n",
    "    except:\n",
    "        return country, 0\n",
    "    \n",
    "# Function to calculate age from birthdate\n",
    "def calculateAge(birthDate):\n",
    "    try:\n",
    "        today = datetime.today()\n",
    "        age = today.year - birthDate.year -((today.month, today.day) <(birthDate.month, birthDate.day))    \n",
    "    except:\n",
    "        return None\n",
    "    return age\n",
    "\n",
    "# Function to normalize sizes like \"4XL\" into \"XXXXL\" for XLs and XSs\n",
    "def normalize_size(size):\n",
    "    match = re.match(r\"(\\d+)(XL)\", size.upper().strip())\n",
    "    match_2 = re.match(r\"(\\d+)(XS)\", size.upper().strip())\n",
    "    if match:\n",
    "        number = int(match.group(1))\n",
    "        return \"X\" * number + \"L\"\n",
    "    elif match_2:\n",
    "        number = int(match_2.group(1))\n",
    "        return \"X\" * number + \"S\"\n",
    "    else:\n",
    "        return size.strip()\n",
    "    \n",
    "# Function to convert clothes sizes to numerical values\n",
    "def convert_size_to_numbers(sizes):\n",
    "    if pd.isna(sizes):\n",
    "        return 0\n",
    "    sizes = sizes.split(',')\n",
    "    numeric_sizes = [size_mapping[size.strip()] for size in sizes if size.strip() in size_mapping]\n",
    "    return numeric_sizes if numeric_sizes else None\n",
    "\n",
    "# Function to convert personality types to numerical values\n",
    "def convert_personality_to_number(personality):\n",
    "    for key in personality_mapping:\n",
    "        if key == personality:\n",
    "            return personality_mapping[key]\n",
    "    return 4\n",
    "    \n",
    "#Function to get valid color as per capital lettes\n",
    "def split_by_capital(s):\n",
    "    if len(s.split(\" \")) == 1 and s[0].isupper() and s[1].islower():\n",
    "        # Split the string at each point a new capital letter starts, except for the very beginning of the string\n",
    "        parts = re.findall('[A-Z][^A-Z]*', s)\n",
    "        return parts\n",
    "    else:\n",
    "        return s.split(\" \")\n",
    "\n",
    "#Function to extract and convert color to rgba\n",
    "def custom_to_rgba(name):\n",
    "    try:\n",
    "        int32_values = []\n",
    "        color_name_2=[]\n",
    "        # Split the string based on capital letters\n",
    "        color_name = split_by_capital(name)\n",
    "        color_name  = [i for i in color_name if len(i)>2]\n",
    "        for i in color_name:\n",
    "            i = i.rstrip('s') #handle words like \"blacks\"\n",
    "            i = i.rstrip('ish') #handle words like \"blackish\"\n",
    "            if spell.correction(i.lower()) is None:\n",
    "                color_name_2.append(i.lower())\n",
    "            else:\n",
    "                color_name_2.append(spell.correction(i.lower()))\n",
    "                color_name_2.append(i.lower().strip())\n",
    "        color_names_3  = [i for i in color_name_2 if Color(i) is True]\n",
    "        if len(color_names_3) <= 0:\n",
    "            color_names_3 = color_name_2\n",
    "        color_names_3 = list(set(color_names_3))\n",
    "        for color_name_3 in color_names_3:\n",
    "            color_name_3 = color_name_3.lower().replace(\" \", \"\").strip()\n",
    "            #Handle common typo errors\n",
    "            if color_name_3.startswith(\"b\") and color_name_3.endswith(\"ck\"):\n",
    "                color_name_3 = \"black\"\n",
    "            elif color_name_3.startswith(\"whit\"):\n",
    "                color_name_3 = \"white\"\n",
    "            elif color_name_3.startswith(\"bl\") and color_name_3.endswith(\"ck\") == False:\n",
    "                color_name_3 = \"blue\"   \n",
    "            elif color_name_3.startswith(\"voil\"):\n",
    "                color_name_3 = \"violet\" \n",
    "            elif color_name_3.startswith(\"ros\") or color_name_3.endswith(\"ink\"):\n",
    "                color_name_3 = \"pink\"  \n",
    "            elif color_name_3.endswith(\"ojo\") or color_name_3.startswith(\"verm\"):\n",
    "                color_name_3 = \"red\"   \n",
    "            elif color_name_3.startswith(\"verd\"):\n",
    "                color_name_3 = \"green\"  \n",
    "            elif color_name_3.startswith(\"azu\"):\n",
    "                color_name_3 = \"blue\"\n",
    "            elif color_name_3.startswith(\"negr\") or color_name_3.startswith(\"ne\"):\n",
    "                color_name_3 = \"black\"\n",
    "            elif color_name_3.startswith(\"bian\"):\n",
    "                color_name_3 = \"white\"\n",
    "            elif color_name_3.startswith(\"saf\") and color_name_3.endswith(\"on\"):\n",
    "                color_name_3 = \"orange\"\n",
    "            elif \"denim\" in color_name_3 or \"jean\" in color_name_3:\n",
    "                color_name_3 = \"blue\"\n",
    "            try:\n",
    "                rgba = colors.to_rgba(color_name_3)\n",
    "                int32_values.append(list(rgba))\n",
    "            except:\n",
    "                #some common color not handled by matplotlib.color module\n",
    "                if color_name_3 == \"mauve\":\n",
    "                    rgba = (213, 184, 255, 1)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3.startswith(\"lil\") :\n",
    "                    rgba = (157,126,183,1.00)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3.startswith(\"peac\"):\n",
    "                    rgba = (255,176,124,1.00)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3 == \"cream\":\n",
    "                    rgba = (245,239,214,1.00)\n",
    "                    int32_values.append(list(rgba)) \n",
    "                elif (color_name_3.startswith(\"b\") and color_name_3.endswith(\"ge\")) or color_name_3.startswith(\"offw\"):\n",
    "                    rgba = (245, 245, 220, 1)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3 == \"burgundy\":\n",
    "                    rgba =(144,0,32,1.00)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3 == \"nude\":\n",
    "                    rgba =(227, 188, 154, 1.00)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3 == \"khaki\" or color_name_3 == \"kakhi\" or color_name_3 == \"kaki\" or color_name_3 == \"olive\":\n",
    "                    rgba =(181, 179, 92, 1)\n",
    "                    int32_values.append(list(rgba))\n",
    "                elif color_name_3.startswith(\"sand\") or color_name_3 == \"mustard\":\n",
    "                    rgba =(231,196,150, 1)\n",
    "                    int32_values.append(list(rgba))\n",
    "        if len(int32_values) < 1:\n",
    "            raise Exception\n",
    "        else:\n",
    "            return int32_values\n",
    "    except Exception:\n",
    "        rgba = (0, 0, 0, 1)\n",
    "        int32_values.append(list(rgba))\n",
    "        return int32_values\n",
    "\n",
    "#Function to remove braceted text\n",
    "def remove_bracketed_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return re.sub(r'\\(.*?\\)', '', text).strip()\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "#Function to extract type from Clothing_type column\n",
    "def replace_clothing_type(text):\n",
    "    text = text.lower()  \n",
    "    if 'street' in text:\n",
    "        return 'streetwear'\n",
    "    elif 'sport' in text:\n",
    "        return 'sportswear'\n",
    "    elif 'dress' in text or 'saree' in text or 'sadi' in text or 'traditional' in text or 'religi' in text:\n",
    "        return 'traditional'\n",
    "    elif 'offic' in text or 'formal' in text:\n",
    "        return 'formal'\n",
    "    elif 'athleisure' in text:\n",
    "        return 'casual'\n",
    "    elif 'basic' in text or 'casual' in text or 'smart' in text:\n",
    "        return 'casual'\n",
    "    elif 'party' in text:\n",
    "        return 'partywear'\n",
    "    elif text in allowed_types:\n",
    "        return text\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "#Function to convert RGBA to color\n",
    "def rgba_to_named_color(rgba):\n",
    "    min_dist = float('inf')\n",
    "    closest_color = None\n",
    "    rgba = np.append(rgba,[1])\n",
    "    for name, hex_color in colors.CSS4_COLORS.items():\n",
    "        # Convert hex to RGBA\n",
    "        color_rgba = colors.to_rgba(hex_color)\n",
    "        \n",
    "        # Calculate the distance between the colors\n",
    "        dist = np.linalg.norm(np.array(color_rgba) - np.array(rgba))\n",
    "        \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_color = name    \n",
    "    return closest_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fac7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.689908Z",
     "iopub.status.busy": "2024-09-05T15:22:28.689769Z",
     "iopub.status.idle": "2024-09-05T15:22:28.803551Z",
     "shell.execute_reply": "2024-09-05T15:22:28.803093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,695 : INFO : [948062006.py:5] : Loading inputs\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Load the inputs ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Loading inputs') \n",
    "    df = pd.read_excel(os.path.join(input_folder, \"input.xlsx\"))\n",
    "    country_map = pd.read_excel(os.path.join(input_folder, \"country_to_lat_long.xlsx\"))\n",
    "    \n",
    "    # dictionary to map the current column names to new names\n",
    "    new_column_names = {'Country of Birth': 'Country_of_Birth',\n",
    "        'Country of Residence': 'Country_of_Residence',\n",
    "        'Birthdate': 'Birthdate',\n",
    "        'Gender': 'Gender',\n",
    "        'Approximate weight in kilogram': 'Weight_kg',\n",
    "        'Approximate height in centimetre': 'Height_cm',\n",
    "        'What type of clothes you prefer to wear': 'Preferred_Clothing_Type',\n",
    "        'How do you define yourself': 'Personality',\n",
    "        'Size of clothes you wear': 'Clothing_Size',\n",
    "        'What is your favourite color.': 'Favourite_Color',\n",
    "        'Do you think this color looks best on you and boost your confidence?': 'Color_Boost_Confidence',\n",
    "        'Which color do you think looks best on you and makes you feel confident?': 'Best_Color_Confidence'}\n",
    "    \n",
    "    # Define a mapping from size to a numerical value using the provided values\n",
    "    size_mapping = {'XXXXXS': 1, 'XXXXS': 2, 'XXXS': 3, 'XXS': 4, 'XS': 5, 'S': 6, 'M': 7, 'L': 8,\n",
    "                    'XL': 9, 'XXL': 10, 'XXXL': 11, 'XXXXL': 12, 'XXXXXL': 13}\n",
    "    \n",
    "    personality_mapping = {'Introvert (Are you shy, reticent person?)': 1,\n",
    "        'Ambivert (Are you able to balance between extrovert and introvert?)': 2,\n",
    "        'Extrovert (Are you outgoing, socially confident?)': 3,}\n",
    "    \n",
    "    allowed_types = ['semiformal', 'casual', 'formal', 'partywear', 'traditional', 'sportswear', 'streetwear']\n",
    "    \n",
    "    # Define the mapping for the 'Preferred_clothing' column\n",
    "    preferred_clothing_mapping = {'Single Piece Wear': 0, 'Two Piece Wear': 1}\n",
    "    \n",
    "    columns_to_process = ['Preferred_Bottoms', 'Bottoms_Material', 'Bottoms_Length', 'Bottoms_Fitting', 'Bottoms_Color', \n",
    "        'Preferred_Upperwear', 'Upperwear_Material', 'Upperwear_Length', 'Upperwear_Neckline', 'Upperwear_Sleeve_Type', \n",
    "        'Upperwear_Pattern', 'Upperwear_Color', 'Favourite_Single_Piece', 'Single_Piece_Material', \n",
    "        'Single_Piece_Fitting', 'Single_Piece_Length', 'Single_Piece_Sleeves', 'Single_Piece_Neckline', \n",
    "        'Single_Piece_Pattern', 'Single_Piece_Color']\n",
    "\n",
    "    #output columns\n",
    "    columns_to_process = ['Preferred_Bottoms', 'Bottoms_Material', 'Bottoms_Length', 'Bottoms_Fitting', 'Bottoms_Color', \n",
    "        'Preferred_Upperwear', 'Upperwear_Material', 'Upperwear_Length', 'Upperwear_Neckline', 'Upperwear_Sleeve_Type', \n",
    "        'Upperwear_Pattern', 'Upperwear_Color', 'Favourite_Single_Piece', 'Single_Piece_Material', \n",
    "        'Single_Piece_Fitting', 'Single_Piece_Length', 'Single_Piece_Sleeves', 'Single_Piece_Neckline', \n",
    "        'Single_Piece_Pattern', 'Single_Piece_Color']\n",
    "    \n",
    "    # Rename the columns in the DataFrame\n",
    "    df.rename(columns=new_column_names, inplace=True)\n",
    "    #handle country names\n",
    "    country_name_dic = {\"Uk\":\"United Kingdom\", \n",
    "                                    \"Usa\": \"United States\",\n",
    "                                    \"Us\":\"United States\",\n",
    "                                    \"America\":\"United States\",\n",
    "                                    \"United States Of America\": \"United States\",\n",
    "                                    \"United State Of America\" : \"United States\",\n",
    "                                    \"United States Of American\":\"United States\",\n",
    "                                   \"England\": \"United Kingdom\",\n",
    "                                   \"Wales\":\"United Kingdom\",\n",
    "                                   \"Scotland\":\"United Kingdom\",\n",
    "                                   \"Ksa\": \"Saudi Arabia\",\n",
    "                                   \"Rsa\": \"South Africa\",\n",
    "                                   \"Great Britain\":\"United Kingdom\",\n",
    "                                   \"Britain\": \"United Kingdom\",\n",
    "                                   \"Uae\":\"United Arab Emirates\",\n",
    "                                   \"United Kingdom Of Great Britain And Northern Ireland\":\"United Kingdom\",\n",
    "                                \"Mumbai\":\"India\",\n",
    "                                \"Czechia\": \"Czech Republic\",\n",
    "                                \"Bharat\":\"India\",\n",
    "                                \"Edinburgh\":\"United Kingdom\",\n",
    "                                \"Korea\":\"South Korea\",\n",
    "                                \"Russian Federation\": \"Russia\",\n",
    "                                \"Thane\":\"India\",\n",
    "                                \"Dubai\": \"United Arab Emirates\",\n",
    "                                \"Democratic Republic Of Congo\": \"Congo\",\n",
    "                                \"Europe\":\"United Kingdom\",\n",
    "                                \"Italia\":\"Italy\",\n",
    "                                \"Sssr\" : \"Russia\"}\n",
    "\n",
    "except Exception as err:\n",
    "    audit_logger.info('Loading inputs - Failed')\n",
    "    error_logger.error('Loading inputs - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff44289e-c2bc-498f-ac7e-f6e9efdf79be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.806084Z",
     "iopub.status.busy": "2024-09-05T15:22:28.805906Z",
     "iopub.status.idle": "2024-09-05T15:22:28.875308Z",
     "shell.execute_reply": "2024-09-05T15:22:28.874887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,825 : INFO : [406014992.py:5] : Data Preprocessing\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Data Preprocessing ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Data Preprocessing')\n",
    "\n",
    "    df.loc[df['Country_of_Residence'] == 'Same as Country of Birth', 'Country_of_Residence'] = df['Country_of_Birth']\n",
    "    df.loc[df['Color_Boost_Confidence'] == 'Yes', 'Best_Color_Confidence'] = df['Favourite_Color']\n",
    "    \n",
    "    df[\"Color_Boost_Confidence\"].replace({\"Yes\":1, \"No\":0}, inplace=True)\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].astype(str)\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].astype(str)   \n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].str.strip().str.title()\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].str.strip().str.title()\n",
    "    \n",
    "    # Create a list of official country names\n",
    "    country_names = [country.name for country in pycountry.countries]\n",
    "    alpha_2_mapping = {country.alpha_2.title(): country.name.title() for country in pycountry.countries}\n",
    "    \n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x) if isinstance(x, str) else x)\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].apply(lambda x: x.split(\",\")[-1] if isinstance(x, str) else x)\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].str.title()\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].apply(lambda x:x.replace(\"The \", \"\"))\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].apply(lambda x:\"Us\" if x.find(\"America\") != -1 else x)\n",
    "    \n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x) if isinstance(x, str) else x)\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].apply(lambda x: x.split(\",\")[-1] if isinstance(x, str) else x)\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].str.title()\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].apply(lambda x:x.replace(\"The \", \"\"))\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].apply(lambda x:\"Us\" if x.find(\"America\") != -1 else x)\n",
    "    \n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].replace(country_name_dic)\n",
    "    \n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].replace(country_name_dic)\n",
    "    \n",
    "    # Replace blank, NaN, or unreadable entries in 'Country_of_Birth' with 'Country_of_Residence' and vice versa\n",
    "    df[\"Country_of_Birth\"] = df[\"Country_of_Birth\"].apply(lambda x: np.nan if isinstance(x, str) and x.strip() in ['', 'Cannot Read Text'] else x)\n",
    "    df[\"Country_of_Residence\"] = df[\"Country_of_Residence\"].apply(lambda x: np.nan if isinstance(x, str) and x.strip() in ['', 'Cannot Read Text'] else x)\n",
    "    df[\"Country_of_Birth\"].fillna(df[\"Country_of_Residence\"], inplace=True)\n",
    "    df[\"Country_of_Residence\"].fillna(df[\"Country_of_Birth\"], inplace=True)\n",
    "    \n",
    "    # Get the unique values from the 'Country_of_Birth' column\n",
    "    unique_countries_1 = list(df['Country_of_Birth'].unique())\n",
    "    unique_countries_2 = list(df['Country_of_Residence'].unique())\n",
    "    unique_countries = np.union1d(unique_countries_1, unique_countries_2)\n",
    "    \n",
    "    # Apply the function to the unique values\n",
    "    matched_countries = {country: get_best_match_with_confidence(country) for country in unique_countries}\n",
    "    \n",
    "    # Create two new columns in the DataFrame by mapping the results back to the original 'Country_of_Birth' column\n",
    "    df['Country_of_Birth'] = df['Country_of_Birth'].apply(lambda x: matched_countries[x][0] if x in matched_countries else x)\n",
    "    df['Country_of_Residence'] = df['Country_of_Residence'].apply(lambda x: matched_countries[x][0] if x in matched_countries else x)\n",
    "    \n",
    "    # Create a mapping from country names to numerical values\n",
    "    country_mapping = {country: idx + 1 for idx, country in enumerate(unique_countries)}\n",
    "    \n",
    "    unique_countries_1 = list(df['Country_of_Birth'].unique())\n",
    "    unique_countries_2 = list(df['Country_of_Residence'].unique())\n",
    "    unique_countries = np.union1d(unique_countries_1, unique_countries_2)\n",
    "    \n",
    "    country_map['name'] = country_map['name'].str.strip().str.lower().str.replace(' ', '', regex=True).str.replace(r\"\\s*\\([^()]*\\)\", \"\", regex=True)\n",
    "    \n",
    "    country_map = country_map.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    countries_normalized = np.char.replace(np.char.strip(np.char.lower(unique_countries)), ' ', '')\n",
    "    \n",
    "    # Create a dictionary from the DataFrame for quick lookup\n",
    "    country_dict = dict(zip(country_map['name'], zip(country_map['latitude'], country_map['longitude'])))\n",
    "    \n",
    "    # Map the countries in the array to their coordinates using the dictionary\n",
    "    coordinates = [country_dict.get(country, (None, None)) for country in countries_normalized]\n",
    "    \n",
    "    # Convert to DataFrame for better visualization or further use\n",
    "    coordinates_df = pd.DataFrame(coordinates, columns=['Latitude', 'Longitude'], index=unique_countries).reset_index()\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.merge(coordinates_df, left_on='Country_of_Birth', right_on='index')\n",
    "    df = df.set_index(df[\"index_x\"])\n",
    "    df.drop(columns=[\"index_x\",\"index_y\", \"Country_of_Birth\"], inplace=True)\n",
    "    df.rename(columns={'Latitude': 'birthplace_lat', 'Longitude': 'birthplace_lon'}, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.merge(coordinates_df, left_on='Country_of_Residence', right_on='index')\n",
    "    df = df.set_index(df[\"index_x\"])\n",
    "    df.drop(columns=[\"index_x\",\"index\", \"Country_of_Residence\"], inplace=True)\n",
    "    df.rename(columns={'Latitude': 'resi_lat', 'Longitude': 'resi_lon'}, inplace=True)                                                             \n",
    "    df['resi_lat'].fillna(df['birthplace_lat'], inplace=True)\n",
    "    df['birthplace_lat'].fillna(df['resi_lat'], inplace=True)\n",
    "    df['resi_lon'].fillna(df['birthplace_lon'], inplace=True)\n",
    "    df['birthplace_lon'].fillna(df['resi_lon'], inplace=True)\n",
    "\n",
    "    df['Birthdate'] = pd.to_datetime(df['Birthdate'], errors='coerce')\n",
    "    df['Age'] = df['Birthdate'].apply(calculateAge)\n",
    "    \n",
    "    df['Weight_kg'] = df['Weight_kg'].apply(lambda x: x * 100 if x < 1 else x)\n",
    "    df['Weight_kg'] = df['Weight_kg'].apply(lambda x: x * 10 if x < 10 else x)\n",
    "    df[\"Weight_kg\"] = df[\"Weight_kg\"].round(0)\n",
    "    \n",
    "    df['Height_cm'] = df['Height_cm'].apply(lambda x: x * 100 if x < 2 else x)\n",
    "    df['Height_cm'] = df['Height_cm'].apply(lambda x: x * 30.48 if x < 15 else x)\n",
    "    df['Height_cm'] = df['Height_cm'].apply(lambda x: x * 2.54 if x < 100 else x)\n",
    "    df[\"Height_cm\"] = df[\"Height_cm\"].round(0)\n",
    "    \n",
    "    # Normalize the sizes in the 'Size of clothes you wear' column\n",
    "    df['Clothing_Size'] = df['Clothing_Size'].apply(lambda sizes: ','.join([normalize_size(size) for size in sizes.split(',')]))\n",
    "    \n",
    "    # Apply the function to the 'Size of clothes you wear' column\n",
    "    df['Clothing_Size'] = df['Clothing_Size'].apply(convert_size_to_numbers)\n",
    "    \n",
    "    # Apply the function to the 'How do you define yourself' column\n",
    "    df['Personality'] = df['Personality'].apply(convert_personality_to_number)\n",
    "    \n",
    "    df['Favourite_Color'] = df['Favourite_Color'].str.split(',')\n",
    "    df['Best_Color_Confidence'] = df['Best_Color_Confidence'].str.split(',')\n",
    "    df = df.explode('Favourite_Color')\n",
    "    df = df.explode(\"Clothing_Size\")\n",
    "    df = df.explode(\"Best_Color_Confidence\")\n",
    "    \n",
    "    df[\"Favourite_Color\"] = df[\"Favourite_Color\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', ' ', x) if isinstance(x, str) else x)\n",
    "    df['Favourite_Color'] = df['Favourite_Color'].apply(custom_to_rgba)\n",
    "    df[\"Best_Color_Confidence\"] = df[\"Best_Color_Confidence\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x) if isinstance(x, str) else x)\n",
    "    df['Best_Color_Confidence'] = df['Best_Color_Confidence'].apply(custom_to_rgba)                                                   \n",
    "    df = df.explode('Favourite_Color')\n",
    "    df = df.explode(\"Best_Color_Confidence\")\n",
    "    df[['Favourite_Color_r', 'Favourite_Color_g', 'Favourite_Color_b', 'Favourite_Color_a']] = pd.DataFrame(df['Favourite_Color'].tolist(), index=df.index)\n",
    "    df[['Best_Color_Confidence_r', 'Best_Color_Confidence_g', 'Best_Color_Confidence_b', 'Best_Color_Confidence_a']] = pd.DataFrame(df['Favourite_Color'].tolist(), index=df.index)\n",
    "    \n",
    "    df['Gender'] = df['Gender'].apply(lambda x: 1 if x.lower() == 'male' else (3 if x.lower() == 'female' else 2))\n",
    "    \n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(lambda x:str(x).lower().strip())\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(remove_bracketed_text)\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(lambda x:x.replace(\"both\", \"\").replace(\"combination\", \"\").replace(\"smart\", \"\"))\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].str.split('and')\n",
    "    df = df.explode(\"Preferred_Clothing_Type\")\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].str.split('/')\n",
    "    df = df.explode(\"Preferred_Clothing_Type\")\n",
    "    # Apply the function to a specific column, e.g., 'How do you define yourself'\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(remove_stop_words)\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(lambda x:x.replace(\" \", \"\"))\n",
    "    # Apply the function to the cleaned column\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].apply(replace_clothing_type)\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].str.split(',')\n",
    "    df = df.explode('Preferred_Clothing_Type')\n",
    "    with open(os.path.join(saved_folder, 'Preferred_Clothing_Type.json'), 'r') as f:\n",
    "        clothing_type_mapping = json.load(f)\n",
    "    # Apply the function to the final cleaned column\n",
    "    df['Preferred_Clothing_Type'] = df['Preferred_Clothing_Type'].map(clothing_type_mapping)\n",
    "    \n",
    "    df = df[['Gender', 'Weight_kg', 'Height_cm','Preferred_Clothing_Type', 'Personality', 'Clothing_Size','Favourite_Color_r', \n",
    "             'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', 'Best_Color_Confidence_g','Best_Color_Confidence_b', \n",
    "             'birthplace_lat', 'birthplace_lon', 'resi_lat', 'resi_lon', 'Age',]]\n",
    "    df.fillna(0, inplace=True)\n",
    "except Exception as err:\n",
    "    audit_logger.info('Data Preprocessing - Failed')\n",
    "    error_logger.error('Data Preprocessing - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ad31c7-3d47-4ee7-9756-c5689850759b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.877470Z",
     "iopub.status.busy": "2024-09-05T15:22:28.877318Z",
     "iopub.status.idle": "2024-09-05T15:22:28.939756Z",
     "shell.execute_reply": "2024-09-05T15:22:28.939355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,879 : INFO : [98284998.py:5] : Cluster Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,937 : INFO : [98284998.py:18] : index_x\n",
      "0    1\n",
      "Name: Cluster, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Cluster model ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Cluster Model')\n",
    "    scaler = load(os.path.join(saved_folder, 'scaler_1.joblib'))\n",
    "    kmeans = load(os.path.join(saved_folder, 'kmeans_model.joblib'))\n",
    "    \n",
    "    data_for_cluster = df[['Gender', 'Weight_kg', 'Height_cm','Preferred_Clothing_Type', 'Clothing_Size',\n",
    "                           'Favourite_Color_r', 'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', \n",
    "                           'Best_Color_Confidence_g','Best_Color_Confidence_b', 'birthplace_lat','birthplace_lon', \n",
    "                           'resi_lat', 'resi_lon', 'Age', 'Personality']]\n",
    "    features_scaled = scaler.transform(data_for_cluster)\n",
    "    \n",
    "    # Predict the cluster for the new data\n",
    "    cluster = kmeans.predict(features_scaled)\n",
    "    df[\"Cluster\"] = cluster\n",
    "    audit_logger.info(df[\"Cluster\"])\n",
    "except Exception as err:\n",
    "    audit_logger.info('Cluster Model - Failed')\n",
    "    error_logger.error('Cluster Model - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b18fd9-9831-4f81-a8d9-30fdd3fa3c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:28.941795Z",
     "iopub.status.busy": "2024-09-05T15:22:28.941643Z",
     "iopub.status.idle": "2024-09-05T15:22:29.268335Z",
     "shell.execute_reply": "2024-09-05T15:22:29.267553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:28,944 : INFO : [1993931470.py:5] : Model for Preferred_clothing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:29,263 : INFO : [1993931470.py:20] : index_x\n",
      "0    0\n",
      "Name: Preferred_Clothing, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Model for Preferred_clothing ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Model for Preferred_clothing')\n",
    "    X_train_1 = df[['Gender', 'Weight_kg', 'Height_cm','Preferred_Clothing_Type', 'Clothing_Size',\n",
    "                       'Favourite_Color_r', 'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', \n",
    "                       'Best_Color_Confidence_g','Best_Color_Confidence_b', 'birthplace_lat','birthplace_lon', 'Cluster',\n",
    "                       'resi_lat', 'resi_lon', 'Age', 'Personality']]\n",
    "    X_train_1[\"Clothing_Size\"] = X_train_1[\"Clothing_Size\"].astype(int)\n",
    "    # Load the saved models\n",
    "    rf_model = load(os.path.join(saved_folder,'random_forest_model_stage_1.joblib'))\n",
    "    lgb_model = load(os.path.join(saved_folder,'lightgbm_model_stage_1.joblib'))\n",
    "    \n",
    "    rf_probs = rf_model.predict_proba(X_train_1)[:, 1]\n",
    "    lgb_probs = lgb_model.predict_proba(X_train_1)[:, 1]\n",
    "    blended_probs = (rf_probs + lgb_probs) / 2\n",
    "    final_predictions = (blended_probs > 0.5).astype(int)\n",
    "    df[\"Preferred_Clothing\"] = final_predictions\n",
    "    audit_logger.info(df[\"Preferred_Clothing\"])\n",
    "    df_2 = df[df[\"Preferred_Clothing\"] == 1]\n",
    "    df_1 = df[df[\"Preferred_Clothing\"] == 0]\n",
    "except Exception as err:\n",
    "    audit_logger.info('Model for Preferred_clothing - Failed')\n",
    "    error_logger.error('Model for Preferred_clothing - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78041653-215d-4807-887b-dcca38f9b118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:29.271900Z",
     "iopub.status.busy": "2024-09-05T15:22:29.271634Z",
     "iopub.status.idle": "2024-09-05T15:22:29.283863Z",
     "shell.execute_reply": "2024-09-05T15:22:29.283319Z"
    }
   },
   "outputs": [],
   "source": [
    "#==================================================================================================\n",
    "### Model for Two piece clothing ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    if len(df_2) > 0:\n",
    "        audit_logger.info('Model for Two piece clothing')\n",
    "        multiclass_model_2 = load(os.path.join(saved_folder, 'multiclass_random_forest_2_stage_2.joblib'))\n",
    "    \n",
    "        column_y=['Preferred_Bottoms', 'Bottoms_Material', 'Bottoms_Length', 'Bottoms_Fitting', 'Preferred_Upperwear',\n",
    "                                               'Upperwear_Material', 'Upperwear_Length', 'Upperwear_Neckline', 'Upperwear_Sleeve_Type', 'Upperwear_Pattern']\n",
    "        \n",
    "        X_twopiece = df_2[['Gender', 'Weight_kg', 'Height_cm', 'Preferred_Clothing_Type','Personality', 'Clothing_Size','Favourite_Color_r', \n",
    "              'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', 'Best_Color_Confidence_g','Best_Color_Confidence_b', \n",
    "              'birthplace_lat', 'birthplace_lon', 'resi_lat', 'resi_lon', 'Age']]\n",
    "    \n",
    "        y_pred = multiclass_model_2.predict(X_twopiece)\n",
    "        y_pred_df = pd.DataFrame(y_pred, columns=column_y)\n",
    "        y_pred_df.index = X_twopiece.index  # Adjust the index if necessary\n",
    "    \n",
    "        result_df_2 = pd.concat([X_twopiece, y_pred_df], axis=1)\n",
    "        for col in column_y:\n",
    "            with open(os.path.join(saved_folder, col+'.json'), 'r') as f:\n",
    "                mapping = json.load(f)\n",
    "            reversed_mapping = {value: key for key, value in mapping.items()}\n",
    "            result_df_2[col] = result_df_2[col].map(reversed_mapping)\n",
    "        result_df_2[\"Preferred_Clothing\"] = 'Two Piece Wear'\n",
    "    \n",
    "        X_twopiece = df_2[['Gender', 'Weight_kg', 'Height_cm', 'Preferred_Clothing_Type', 'Personality', 'Clothing_Size',\n",
    "                       'Favourite_Color_r', 'Favourite_Color_g', 'Favourite_Color_b', 'Best_Color_Confidence_r',\n",
    "                       'Best_Color_Confidence_g', 'Best_Color_Confidence_b', 'birthplace_lat', 'birthplace_lon',\n",
    "                       'resi_lat', 'resi_lon', 'Age']]\n",
    "    \n",
    "        scaler_X_twop = load(os.path.join(saved_folder, 'scaler_X_twop.joblib'))\n",
    "        scaler_y_twop = load(os.path.join(saved_folder, 'scaler_y_twop.joblib'))\n",
    "    \n",
    "        X_twopiece = scaler_X_twop.transform(X_twopiece)\n",
    "    \n",
    "        # Reshape input to be [samples, features, 1] if your model expects 3D input (e.g., CNN, LSTM)\n",
    "        X_twopiece = X_twopiece.reshape((X_twopiece.shape[0], X_twopiece.shape[1], 1))\n",
    "    \n",
    "        from tensorflow.keras.models import load_model\n",
    "        color_model_1 = load_model(os.path.join(saved_folder, 'cnn_model_twopiece_standard.h5'))\n",
    "        \n",
    "        y_pred = color_model_1.predict(X_twopiece)\n",
    "        \n",
    "        y_pred_rescaled = scaler_y_twop.inverse_transform(y_pred)\n",
    "    \n",
    "        bottoms = []\n",
    "        upperwear = []\n",
    "        for i in y_pred_rescaled:\n",
    "            bottoms.append(rgba_to_named_color(i[1:4]))\n",
    "            upperwear.append(rgba_to_named_color(i[5:]))\n",
    "                    \n",
    "        result_df_2[\"Bottoms_Color\"] = bottoms\n",
    "        result_df_2[\"Upperwear_Color\"] = upperwear\n",
    "        # Create a sentence for lowerwear\n",
    "        result_df_2['Bottoms'] = result_df_2[\"Bottoms_Color\"].astype(str) + \" \" + \\\n",
    "                             result_df_2['Bottoms_Fitting'].astype(str) + \" fit \" + \\\n",
    "                             result_df_2['Bottoms_Length'].astype(str) + \" length \" + \\\n",
    "                             result_df_2['Bottoms_Material'].astype(str) + \" \" + \\\n",
    "                             result_df_2['Preferred_Bottoms'].astype(str)\n",
    "        result_df_2['Bottoms'] = result_df_2['Bottoms'].apply(lambda x: str(x).lower().replace(\" any length \", \" \").replace(\" any fit \", \" \").replace(\" any \", \" \"))\n",
    "        result_df_2['Bottoms'] = result_df_2['Bottoms'].apply(lambda x: str(x).lower().replace(\" nan length \", \" \").replace(\" nan fit \", \" \").replace(\" nan \", \" \"))\n",
    "\n",
    "        \n",
    "        result_df_2['Upperwear'] = result_df_2['Upperwear_Color'].astype(str) + \" \" + \\\n",
    "                               result_df_2['Upperwear_Sleeve_Type'].astype(str) + \" sleeves \" + \\\n",
    "                                result_df_2['Upperwear_Neckline'].astype(str) + \" neck \" + \\\n",
    "                               result_df_2['Upperwear_Length'].astype(str) + \" length \" + \\\n",
    "                                result_df_2['Upperwear_Pattern'].astype(str) + \" \" + \\\n",
    "                               result_df_2['Upperwear_Material'].astype(str) + \" \" + \\\n",
    "                               result_df_2['Preferred_Upperwear'].astype(str)\n",
    "        \n",
    "        result_df_2['Upperwear'] = result_df_2['Upperwear'].apply(lambda x: str(x).lower().replace(\" any sleeves \", \"\").replace(\" any neck \", \"\").replace(\" any length \", \" \").replace(\" any \", \" \"))\n",
    "        result_df_2['Upperwear'] = result_df_2['Upperwear'].apply(lambda x: str(x).lower().replace(\" nan sleeves \", \"\").replace(\" nan neck \", \"\").replace(\" nan length \", \" \").replace(\" nan \", \" \"))\n",
    "                     \n",
    "except Exception as err:\n",
    "    audit_logger.info('Model for Two piece clothing - Failed')\n",
    "    error_logger.error('Model for Two piece clothing - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc548d2-9383-44a2-8808-49b7ab1f2611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:29.286555Z",
     "iopub.status.busy": "2024-09-05T15:22:29.286311Z",
     "iopub.status.idle": "2024-09-05T15:22:33.806178Z",
     "shell.execute_reply": "2024-09-05T15:22:33.805573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:29,293 : INFO : [3531442730.py:6] : Model for One piece clothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 16:22:32.709234: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-05 16:22:32.712103: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 319ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 16:22:33.670699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Model for One piece clothing ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    if len(df_1) > 0:\n",
    "        audit_logger.info('Model for One piece clothing')\n",
    "        multiclass_model_1 = load(os.path.join(saved_folder,'multiclass_random_forest_1_stage_2.joblib'))\n",
    "    \n",
    "        column_y=['Favourite_Single_Piece', 'Single_Piece_Material', 'Single_Piece_Fitting', 'Single_Piece_Length',\n",
    "              'Single_Piece_Sleeves', 'Single_Piece_Neckline', 'Single_Piece_Pattern']\n",
    "        \n",
    "        X_onepiece = df_1[['Gender', 'Weight_kg', 'Height_cm', 'Preferred_Clothing_Type','Personality', 'Clothing_Size','Favourite_Color_r', \n",
    "              'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', 'Best_Color_Confidence_g','Best_Color_Confidence_b', \n",
    "              'birthplace_lat', 'birthplace_lon', 'resi_lat', 'resi_lon', 'Age']]\n",
    "    \n",
    "        y_pred = multiclass_model_1.predict(X_onepiece)\n",
    "    \n",
    "        y_pred_df = pd.DataFrame(y_pred, columns=column_y)\n",
    "    \n",
    "        y_pred_df.index = X_onepiece.index  # Adjust the index if necessary\n",
    "    \n",
    "        result_df_1 = pd.concat([X_onepiece, y_pred_df], axis=1)\n",
    "        for col in column_y:\n",
    "            with open(os.path.join(saved_folder,col+'.json'), 'r') as f:\n",
    "                mapping = json.load(f)\n",
    "            reversed_mapping = {value: key for key, value in mapping.items()}\n",
    "            result_df_1[col] = result_df_1[col].map(reversed_mapping)\n",
    "        result_df_1[\"Preferred_Clothing\"] = 'One Piece Wear'\n",
    "    \n",
    "        X_onepiece = df_1[['Gender', 'Weight_kg', 'Height_cm', 'Preferred_Clothing_Type', 'Clothing_Size',\n",
    "           'Favourite_Color_r', 'Favourite_Color_g', 'Favourite_Color_b','Best_Color_Confidence_r', 'Best_Color_Confidence_g',\n",
    "            'Best_Color_Confidence_b', 'birthplace_lat', 'birthplace_lon', 'resi_lat', 'resi_lon', 'Age', 'Personality']]\n",
    "    \n",
    "        scaler_X_onep = load(os.path.join(saved_folder,'scaler_X_onep.joblib'))\n",
    "        scaler_y_onep = load(os.path.join(saved_folder,'scaler_y_onep.joblib'))\n",
    "    \n",
    "        X_onepiece = scaler_X_onep.transform(X_onepiece)\n",
    "    \n",
    "        # Reshape input to be [samples, features, 1] if your model expects 3D input (e.g., CNN, LSTM)\n",
    "        X_onepiece = X_onepiece.reshape((X_onepiece.shape[0], X_onepiece.shape[1], 1))\n",
    "    \n",
    "        color_model_1 = load_model(os.path.join(saved_folder,'cnn_model_onepiece.h5'))\n",
    "        \n",
    "        y_pred = color_model_1.predict(X_onepiece)\n",
    "        \n",
    "        y_pred_rescaled = scaler_y_onep.inverse_transform(y_pred)\n",
    "    \n",
    "        singlepiece = []\n",
    "        for i in y_pred_rescaled:\n",
    "            singlepiece.append(rgba_to_named_color(i[1:4]))\n",
    "                    \n",
    "        result_df_1[\"Singlepiece_Color\"] = singlepiece\n",
    "        # Create a sentence for lowerwear\n",
    "        result_df_1['Singlepiece']  = result_df_1['Singlepiece_Color'].astype(str) + \" \" + \\\n",
    "                               result_df_1['Single_Piece_Sleeves'].astype(str) + \" sleeves \" + \\\n",
    "                                result_df_1['Single_Piece_Neckline'].astype(str) + \" neck \" + \\\n",
    "                               result_df_1['Single_Piece_Length'].astype(str) + \" length \" + \\\n",
    "                                result_df_1['Single_Piece_Fitting'].astype(str) + \" fit \" + \\\n",
    "                               result_df_1['Single_Piece_Pattern'].astype(str) + \" \" + \\\n",
    "                                result_df_1['Single_Piece_Material'].astype(str) + \" \" + \\\n",
    "                               result_df_1['Favourite_Single_Piece'].astype(str)\n",
    "        result_df_1['Singlepiece'] = result_df_1['Singlepiece'].apply(lambda x: str(x).lower().replace(\" any sleeves \", \"\").replace(\" any neck \", \"\").replace(\" any length \", \" \").replace(\" any fit \", \" \").replace(\" any \", \" \"))\n",
    "        result_df_1['Singlepiece'] = result_df_1['Singlepiece'].apply(lambda x: str(x).lower().replace(\" nan sleeves \", \"\").replace(\" nan neck \", \"\").replace(\" nan length \", \" \").replace(\" nan fit \", \" \").replace(\" nan \", \" \"))\n",
    "except Exception as err:\n",
    "    audit_logger.info('Model for One piece clothing - Failed')\n",
    "    error_logger.error('Model for One piece clothing - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7879020e-7241-4497-8f7c-a305c00d0ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:33.809473Z",
     "iopub.status.busy": "2024-09-05T15:22:33.809190Z",
     "iopub.status.idle": "2024-09-05T15:22:33.857543Z",
     "shell.execute_reply": "2024-09-05T15:22:33.857190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:33,813 : INFO : [2463263403.py:5] : Final Results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:33,849 : INFO : [2463263403.py:25] :   Country of Birth Country of Residence  Birthdate  Gender  \\\n",
      "0            India                   UK 1996-07-01  Female   \n",
      "\n",
      "   Approximate weight in kilogram  Approximate height in centimetre  \\\n",
      "0                              80                               154   \n",
      "\n",
      "  What type of clothes you prefer to wear  \\\n",
      "0                             Semi Formal   \n",
      "\n",
      "                          How do you define yourself Size of clothes you wear  \\\n",
      "0  Extrovert (Are you outgoing, socially confident?)                       XL   \n",
      "\n",
      "  What is your favourite color.  \\\n",
      "0                        Yellow   \n",
      "\n",
      "  Do you think this color looks best on you and boost your confidence?  \\\n",
      "0                                                 No                     \n",
      "\n",
      "  Which color do you think looks best on you and makes you feel confident?  \\\n",
      "0                                               Pink                         \n",
      "\n",
      "  Preferred_Clothing                                        Singlepiece  \\\n",
      "0     One Piece Wear  black full sleeves collar neck above knee leng...   \n",
      "\n",
      "  Bottoms Upperwear  \n",
      "0      NA        NA  \n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "### Final Results ### \n",
    "#==================================================================================================\n",
    "try:\n",
    "    audit_logger.info('Final Results')\n",
    "    if len(df_1) > 0 and len(df_2) > 0:\n",
    "        result_df = pd.concat([result_df_1, result_df_2])\n",
    "        result_df = result_df[[\"Preferred_Clothing\", \"Singlepiece\", \"Bottoms\", \"Upperwear\"]] \n",
    "    elif len(df_1) > 0:\n",
    "        result_df = result_df_1[[\"Preferred_Clothing\", \"Singlepiece\"]] \n",
    "        result_df[\"Bottoms\"] = \"NA\"\n",
    "        result_df[\"Upperwear\"] = \"NA\"\n",
    "    else:\n",
    "        result_df = result_df_2[[\"Preferred_Clothing\", \"Bottoms\", \"Upperwear\"]] \n",
    "        result_df[\"Singlepiece\"] = \"NA\"\n",
    "    df = pd.read_excel(os.path.join(input_folder, \"input.xlsx\"))\n",
    "    df = df[['Country of Birth', 'Country of Residence', 'Birthdate', 'Gender',\n",
    "           'Approximate weight in kilogram', 'Approximate height in centimetre',\n",
    "           'What type of clothes you prefer to wear', 'How do you define yourself',\n",
    "           'Size of clothes you wear', 'What is your favourite color.',\n",
    "           'Do you think this color looks best on you and boost your confidence?',\n",
    "           'Which color do you think looks best on you and makes you feel confident?']]\n",
    "    result_df = pd.merge(df, result_df, how=\"left\", left_index=True, right_index=True)\n",
    "    result_df.to_excel(os.path.join(output_folder, \"output.xlsx\"))\n",
    "    audit_logger.info(result_df)\n",
    "except Exception as err:\n",
    "    audit_logger.info('Final Results - Failed')\n",
    "    error_logger.error('Final Results - Failed')\n",
    "    error_logger.error('Exception: ', exc_info=True)\n",
    "    #input(\"press Enter to Close\")\n",
    "    sys.exit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08b49a5-4730-40e3-ab1d-da6af50df07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T15:22:33.859646Z",
     "iopub.status.busy": "2024-09-05T15:22:33.859493Z",
     "iopub.status.idle": "2024-09-05T15:22:33.862410Z",
     "shell.execute_reply": "2024-09-05T15:22:33.862084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:33,860 : INFO : [2214019538.py:1] : Process run success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.112 : 2024-09-05 16:22:33,860 : INFO : [2214019538.py:3] : Total time taken = 0:00:05.415354\n"
     ]
    }
   ],
   "source": [
    "audit_logger.info('Process run success')\n",
    "total_time = datetime.now() - curr_time\n",
    "audit_logger.info(f'Total time taken = {total_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
